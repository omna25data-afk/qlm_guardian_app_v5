---
title: استدعاء الأدوات / استدعاء الدوال (شرح الملف)
shortTitle: استدعاء الأدوات
description: >
  تعلم كيفية استخدام "استدعاء الأدوات" (Tool calling)، وإدارة دورات الوكلاء (Agentic loops)، ودمج التفاعلات البشرية مع المعالجة باستخدام حزمة Firebase AI Logic SDK.
---

لا تعرف لنماذج اللغات الكبيرة (LLMs) كل التفاصيل الخاصة أو الأحداث الجارية التي وقعت بعد تدريبها. للتغلب على هذه المشكلة، نقوم بتزويدها بأدوات (Tools) لجمع بيانات أو أداء أفعال معينة.

## تعريف الأداة (Tool defined)

الأداة تُعرّف من خلال اسم، وصف دقيق، ومخطط (JSON Schema) يوضح طبيعة المدخلات التي تحتاجها. عندما يجد النموذج أنه بحاجة لبيانات خارجية، فإنه يقوم بإرسال رسالة "استدعاء أداة" (Tool call) تتضمن اسم الأداة والوسيطات الخاصة بها. يقوم تطبيقك بالرد عبر تنفيذ الدالة داخلياً وإرجاع النتائج للنموذج للاستمرار في إكمال الرد.

## دوال Gemini (Gemini functions)

في حزمة مسار Firebase AI Logic SDK، يُشار للأدوات بمسمى "دوال" (Functions). لبناء أداة تقوم بالتواصل مع واجهة (API) خارجية للبحث عن معاني الكلمات مثلاً:

1. قم بإنشاء دالة باستخدام `FunctionDeclaration` وأضفها كجزء من مكون `tools` أثناء إعداد نموذج الذكاء الاصطناعي.
2. اذكر الغرض من الأداة وحدد أفضل الظروف لاستخدامها في "تعليمات النظام" (System Instructions) لتوجيه النموذج بشكل إضافي للحصول على نتائج دقيقة.

## حلقة الوكيل (The Agentic Loop)

نظراً لأن نماذج LLM عديمة الحالة الدائمة (Stateless)، يجب تمرير التاريخ الكامل للمحادثة في كل طلب لحفظ السياق عند استخدام الأدوات. تتكون الحلقة مما يلي:

* بدء جلسة "شات" لتحتفظ بالسجل (History).
* فحص وجود استدعاء لدوال (Function calls) في الرد.
* تطبيق الدوال برمجياً وجمع نتائجها.
* تغذية النتائج مرة أخرى إلى الـ LLM وتكرار ذلك حتى يقدم النموذج إجابة دون استخدام أدوات إضافية.

## دمج المخرجات المهيكلة مع الأدوات

قد يظهر خطأ (قيد المعالجة من قبل المكتبات) عند محاولة طلب رد من نوع JSON (`application/json`) مع وجود دوال استدعاء (Tools). كحل مؤقت لحل هذه المشكلة: قم بإلغاء التقييد بنسبة لمخرجات JSON الصارمة، ثم أضف دالة أخرى تُسمى `returnResult` (بمخطط الإرجاع المتوقع) واطلب من النموذج أن يقوم باستدعاء تلك الدالة في حال أتم مهمته ليقوم بإرجاع البيانات النهائية فيها، ومن ثم قم باعتراضها وحفظ الرد ضمن المتغيرات داخل الكود.

## دورة المراجعة البشرية (Human in the loop)

يُفضل إبقاء التوقعات في الحسبان بأن الذكاء الاصطناعي قد يعارض المنطق، لذلك نحتاج لاستخدام أداة مثل `resolveConflict` ليطلب تدخل المستخدم البشري. في هذه المرحلة، يتم إيقاف حلقة الوكيل عبر الانتظار (`await`) لحوار تنبيهي UI (`showDialog`) ليتدخل البشر، ثم يعاد الناتج مرة أخرى للنموذج لإكمال الحلقة (Agentic Loop)، وذلك يوضح قوة وسهولة التحكم بالحالة لأن الـ LLM يُمكنه الانتظار لأي وقت طالما تعيد إرسال السجل الخاص به.
